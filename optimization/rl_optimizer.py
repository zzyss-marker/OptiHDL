"""
æ¨¡å—3: RLæ¨ç†ä¼˜åŒ–å™¨
ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†æ—¶ä¼˜åŒ–ï¼Œä¸è®­ç»ƒæ¨¡å‹å‚æ•°
"""

import os
import json
import time
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import numpy as np
from loguru import logger
import sys
import os
import re
from difflib import SequenceMatcher
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core_tools.eda_wrapper import EDAWrapper, analyze_verilog_api


class RLOptimizer:
    """RLæ¨ç†ä¼˜åŒ–å™¨"""
    
    def __init__(self, model_path: str, max_iterations: int = 10, 
                 population_size: int = 1, temperature: float = 0.8,
                 max_new_tokens: int = 1024,
                 debug_gen: bool = False,
                 debug_dir: Optional[str] = None,
                 rl_mode: bool = True,
                 base_top_p: float = 0.9,
                 base_top_k: int = 50,
                 base_rep_penalty: float = 1.05):
        """
        åˆå§‹åŒ–RLä¼˜åŒ–å™¨
        
        Args:
            model_path: è®­ç»ƒå¥½çš„SFTæ¨¡å‹è·¯å¾„
            max_iterations: æœ€å¤§ä¼˜åŒ–è¿­ä»£æ¬¡æ•°
            population_size: æ¯æ¬¡ç”Ÿæˆçš„å€™é€‰ä»£ç æ•°é‡
            temperature: ç”Ÿæˆæ¸©åº¦ï¼Œæ§åˆ¶å¤šæ ·æ€§
        """
        self.model_path = model_path
        self.max_iterations = max_iterations
        self.population_size = population_size
        self.temperature = temperature
        self.max_new_tokens = max_new_tokens
        
        # åŠ è½½æ¨¡å‹
        self.tokenizer, self.model = self._load_model()
        
        # EDAå·¥å…·
        self.eda = EDAWrapper()
        
        # ä¼˜åŒ–å†å²
        self.optimization_history = []
        
        # RL åŠ¨æ€è°ƒæ•´å‚æ•°
        self.rl_mode = rl_mode
        self.base_temperature = temperature
        self.base_top_p = base_top_p
        self.base_top_k = base_top_k
        self.base_rep_penalty = base_rep_penalty
        self.score_history = []  # æ¯è½®æœ€ä½³åˆ†æ•°å†å²
        self.improvement_streak = 0  # è¿ç»­æ”¹è¿›è½®æ•°
        self.stagnation_count = 0   # è¿ç»­æ— æ”¹è¿›è½®æ•°
        self.decline_count = 0      # è¿ç»­ä¸‹é™è½®æ•°
        self.exploration_factor = 0.3  # æ¢ç´¢å› å­
        self.last_best_score = 0.0  # ä¸Šä¸€è½®æœ€ä½³åˆ†æ•°
        self.score_trend = 0.0      # åˆ†æ•°è¶‹åŠ¿
        
        # è°ƒè¯•
        self.debug_gen = debug_gen
        # é»˜è®¤è°ƒè¯•ç›®å½•
        if debug_dir is None and self.debug_gen:
            ts = time.strftime("%Y%m%d_%H%M%S")
            debug_root = Path("outputs") / f"debug_{ts}"
            debug_root.mkdir(parents=True, exist_ok=True)
            self.debug_dir = str(debug_root)
        else:
            self.debug_dir = debug_dir
        
        # æ¨¡å—åï¼ˆå°†åœ¨optimizeæ–¹æ³•ä¸­ä»ä»£ç ä¸­æå–ï¼‰
        self.module_name = None
        
        logger.info(f"RLä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {model_path}")
    
    def _load_model(self) -> Tuple[AutoTokenizer, AutoModelForCausalLM]:
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        logger.info(f"åŠ è½½æ¨¡å‹: {self.model_path}")
        
        tokenizer = AutoTokenizer.from_pretrained(self.model_path)
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯PEFTæ¨¡å‹
        if os.path.exists(os.path.join(self.model_path, "adapter_config.json")):
            # åŠ è½½åŸºç¡€æ¨¡å‹
            with open(os.path.join(self.model_path, "adapter_config.json")) as f:
                adapter_config = json.load(f)
            base_model_name = adapter_config.get("base_model_name_or_path")
            
            base_model = AutoModelForCausalLM.from_pretrained(
                base_model_name,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None,
                trust_remote_code=True
            )
            
            # åŠ è½½PEFTé€‚é…å™¨
            model = PeftModel.from_pretrained(base_model, self.model_path)
            model = model.merge_and_unload()  # åˆå¹¶æƒé‡ä»¥æé«˜æ¨ç†é€Ÿåº¦
        else:
            # ç›´æ¥åŠ è½½å®Œæ•´æ¨¡å‹
            model = AutoModelForCausalLM.from_pretrained(
                self.model_path,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None,
                trust_remote_code=True
            )
        
        model.eval()
        return tokenizer, model
    
    def optimize(self, input_code: str, target_description: str = "") -> Dict[str, Any]:
        """
        ä¼˜åŒ–Verilogä»£ç 
        
        Args:
            input_code: è¾“å…¥çš„Verilogä»£ç 
            target_description: ä¼˜åŒ–ç›®æ ‡æè¿°
        
        Returns:
            ä¼˜åŒ–ç»“æœå­—å…¸
        """
        # æå–æ¨¡å—å
        self.module_name = self._extract_module_name(input_code)
        if not self.module_name:
            return {
                "success": False,
                "error": "æ— æ³•ä»ä»£ç ä¸­æå–æ¨¡å—å"
            }
        
        # åˆå§‹è¯„ä¼°å’Œé¢„æ£€æŸ¥
        logger.info("å¼€å§‹RLä¼˜åŒ–è¿‡ç¨‹")
        try:
            initial_data = self.eda.synthesize(input_code, self.module_name, target_freq=100.0)
        except Exception as e:
            return {
                "success": False,
                "error": f"åˆå§‹ä»£ç ç»¼åˆå¤±è´¥: {str(e)}"
            }
        
        # æ£€æŸ¥åˆå§‹ä»£ç è¯­æ³•å’Œç»¼åˆçŠ¶æ€
        if not initial_data.get("syntax_ok", False) or not initial_data.get("synth_ok", False):
            logger.error("âŒ åˆå§‹ä»£ç è¯­æ³•æˆ–ç»¼åˆæ£€æŸ¥å¤±è´¥ï¼Œåœæ­¢RLè®­ç»ƒ")
            logger.error(f"è¯­æ³•æ£€æŸ¥: {initial_data.get('syntax_ok', False)}")
            logger.error(f"ç»¼åˆæ£€æŸ¥: {initial_data.get('synth_ok', False)}")
            return {
                "success": False,
                "error": "åˆå§‹ä»£ç å­˜åœ¨è¯­æ³•é”™è¯¯æˆ–ç»¼åˆå¤±è´¥ï¼Œæ— æ³•è¿›è¡Œä¼˜åŒ–è®­ç»ƒã€‚è¯·å…ˆä¿®å¤ä»£ç è¯­æ³•é—®é¢˜ã€‚"
            }
        
        initial_score = self._calculate_score(initial_data)
        self.best_score = initial_score
        self.best_code = input_code
        self.best_metrics = initial_data
        self.last_best_score = initial_score
        logger.info(f"âœ… åˆå§‹ä»£ç æ£€æŸ¥é€šè¿‡ï¼Œåˆ†æ•°: {initial_score:.4f}")
        
        # åˆå§‹åŒ–ä¼˜åŒ–å†å²å’Œå˜é‡
        best_score = initial_score
        best_code = input_code
        best_metrics = initial_data
        
        self.optimization_history = [{
            "iteration": 0,
            "code": input_code,
            "metrics": initial_data,
            "score": initial_score,
            "is_best": True
        }]
        
        # è¿­ä»£ä¼˜åŒ–
        for iteration in range(1, self.max_iterations + 1):
            logger.info(f"ä¼˜åŒ–è¿­ä»£ {iteration}/{self.max_iterations}")
            
            # RLåŠ¨æ€è°ƒæ•´ç­–ç•¥
            if self.rl_mode and iteration > 1:
                self._update_rl_strategy(iteration, best_score)
            
            # ç”Ÿæˆå€™é€‰ä»£ç 
            candidates = self._generate_candidates(best_code, target_description, iteration, best_score, best_metrics)
            
            # è¯„ä¼°å€™é€‰ä»£ç 
            iteration_best_score = best_score
            iteration_best_code = best_code
            iteration_best_metrics = best_metrics
            
            for i, candidate in enumerate(candidates):
                logger.info(f"è¯„ä¼°å€™é€‰ä»£ç  {i+1}/{len(candidates)}")
                # é¢„å¤„ç†ï¼šç¡®ä¿å€™é€‰åŒ…å«å®Œæ•´æ¨¡å—å¹¶ä¸åŸºå‡†æ¨¡å—åä¸€è‡´
                module_name = self._detect_top_module(best_code) or "top"
                if not self._has_complete_module(candidate):
                    logger.warning(f"å€™é€‰ä»£ç  {i+1} ç¼ºå°‘å®Œæ•´ module/endmoduleï¼Œä¸¢å¼ƒ")
                    self._maybe_dump_text(iteration, i+1, "extracted_incomplete.v", candidate)
                    continue
                candidate_named = self._try_fix_module_name(candidate, module_name)
                candidate_fixed = self._align_module_header(best_code, candidate_named, module_name)
                # è°ƒè¯•ä¿å­˜
                self._maybe_dump_text(iteration, i+1, "candidate_fixed.v", candidate_fixed)
                
                # å…ˆè¯„ä¼°å€™é€‰ä»£ç è·å–åˆ†æ•°
                metrics_result = self._evaluate_code(candidate_fixed)
                if not metrics_result["success"]:
                    logger.warning(f"å€™é€‰ä»£ç  {i+1} è¯„ä¼°å¤±è´¥: {metrics_result['error']}")
                    continue
                
                metrics = metrics_result["data"]
                score = self._calculate_score(metrics)
                
                # è®°å½•å€™é€‰å†å²ï¼ˆå…ˆè®°å½•å†æ£€æŸ¥ç­‰ä»·ï¼‰
                self.optimization_history.append({
                    "iteration": iteration,
                    "candidate": i+1,
                    "code": candidate_fixed,
                    "metrics": metrics,
                    "score": score,
                    "is_best": False,
                    "equiv_checked": False
                })
                
                logger.info(f"å€™é€‰ {i+1} åˆ†æ•°: {score:.4f} (é¢ç§¯: {metrics['area']}, FF: {metrics.get('num_ff', 0)}, æ·±åº¦: {metrics.get('logic_depth', 0)})")
                
                # ç›´æ¥åŸºäºåˆ†æ•°æ›´æ–°æœ€ä½³å€™é€‰ï¼ˆå·²ç§»é™¤ç­‰ä»·æ£€æŸ¥ï¼‰
                if score > iteration_best_score:
                    logger.info(f"âœ… å€™é€‰ {i+1} åˆ†æ•°æ›´é«˜ï¼Œç›´æ¥é‡‡ç”¨: {score:.4f}")
                    iteration_best_score = score
                    iteration_best_code = candidate_fixed
                    iteration_best_metrics = metrics
                    
                    # ä¿å­˜æœ€ä½³å€™é€‰
                    if self.debug_dir:
                        best_file = Path(self.debug_dir) / f"best_candidate_iter_{iteration}.v"
                        best_file.write_text(candidate_fixed, encoding='utf-8')
                else:
                    decline = (iteration_best_score - score) / max(iteration_best_score, 1e-6) * 100
                    logger.debug(f"å€™é€‰ {i+1} åˆ†æ•°è¾ƒä½: {score:.4f} (ä½ {decline:.2f}%)")
            
            # æ›´æ–°å…¨å±€æœ€ä½³å¹¶è®°å½•RLçŠ¶æ€
            self.score_history.append(iteration_best_score)
            score_change = iteration_best_score - self.last_best_score if self.last_best_score > 0 else 0
            
            if iteration_best_score > best_score:
                best_score = iteration_best_score
                best_code = iteration_best_code
                best_metrics = iteration_best_metrics
                self.improvement_streak += 1
                self.stagnation_count = 0
                improvement = (iteration_best_score - self.last_best_score) / max(self.last_best_score, 1e-6) * 100
                logger.info(f"ğŸ‰ å…¨å±€æœ€ä½³æ›´æ–°: {best_score:.4f} (+{improvement:.2f}%)")
                if self.rl_mode:
                    logger.info(f"RLçŠ¶æ€: è¿ç»­æ”¹è¿› {self.improvement_streak} è½®")
            elif abs(iteration_best_score - best_score) < 1e-6:
                # åˆ†æ•°ç›¸ç­‰ï¼Œè§†ä¸ºåœæ»
                self.improvement_streak = 0
                self.stagnation_count += 1
                logger.info(f"æœ¬è½®æ— æ”¹è¿›ï¼Œç»´æŒæœ€ä½³: {best_score:.4f}")
                if self.rl_mode:
                    logger.info(f"RLçŠ¶æ€: è¿ç»­åœæ» {self.stagnation_count} è½®")
            else:
                # åˆ†æ•°ä¸‹é™
                self.improvement_streak = 0
                self.stagnation_count += 1
                decline = (best_score - iteration_best_score) / max(best_score, 1e-6) * 100
                logger.warning(f"âš ï¸  æœ¬è½®è¡¨ç°ä¸‹é™: {iteration_best_score:.4f} (è¾ƒæœ€ä½³ä½ {decline:.2f}%)")
                if self.rl_mode:
                    logger.warning(f"RLçŠ¶æ€: éœ€è¦è°ƒæ•´ç­–ç•¥ï¼Œåœæ» {self.stagnation_count} è½®")
            
            self.last_best_score = iteration_best_score
        
        # è®¡ç®—æ”¹è¿›æƒ…å†µ
        init_score = self._calculate_score(initial_data)
        improvement = {
            "area_improvement": (initial_data["area"] - best_metrics["area"]) / max(1e-9, initial_data["area"]) * 100,
            "ff_improvement": (initial_data.get("num_ff", 0) - best_metrics.get("num_ff", 0)) / max(1e-9, initial_data.get("num_ff", 0) or 1) * 100,
            "depth_improvement": (initial_data.get("logic_depth", 0) - best_metrics.get("logic_depth", 0)) / max(1e-9, initial_data.get("logic_depth", 0) or 1) * 100,
            "score_improvement": (best_score - init_score) / max(1e-9, init_score or 1) * 100
        }
        
        return {
            "success": True,
            "original_code": input_code,
            "optimized_code": best_code,
            "original_metrics": initial_data,
            "optimized_metrics": best_metrics,
            "improvement": improvement,
            "optimization_history": self.optimization_history,
            "total_iterations": self.max_iterations,
            "total_candidates": len(self.optimization_history) - 1
        }
    
    def _update_rl_strategy(self, iteration: int, current_best_score: float):
        """åŸºäºå†å²è¡¨ç°åŠ¨æ€è°ƒæ•´RLç­–ç•¥"""
        recent_scores = self.score_history[-5:] if len(self.score_history) >= 5 else self.score_history
        
        # è®¡ç®—å¤šå±‚æ¬¡è¶‹åŠ¿
        short_trend = 0.0  # çŸ­æœŸè¶‹åŠ¿ï¼ˆæœ€è¿‘2è½®ï¼‰
        long_trend = 0.0   # é•¿æœŸè¶‹åŠ¿ï¼ˆæœ€è¿‘5è½®ï¼‰
        
        if len(recent_scores) >= 2:
            short_trend = (recent_scores[-1] - recent_scores[-2]) / max(abs(recent_scores[-2]), 1e-6)
        if len(recent_scores) >= 3:
            long_trend = (recent_scores[-1] - recent_scores[0]) / max(abs(recent_scores[0]), 1e-6)
        
        self.score_trend = short_trend
        
        # æ£€æµ‹å¾—åˆ†ä¸‹é™
        if short_trend < -0.01:  # å¾—åˆ†ä¸‹é™è¶…è¿‡1%
            self.decline_count += 1
            logger.warning(f"æ£€æµ‹åˆ°å¾—åˆ†ä¸‹é™: {short_trend:.4f}, è¿ç»­ä¸‹é™ {self.decline_count} è½®")
        else:
            self.decline_count = 0
        
        # åŠ¨æ€è°ƒæ•´ç­–ç•¥ - æ›´æ•æ„Ÿçš„å“åº”
        if self.decline_count >= 2:
            # è¿ç»­ä¸‹é™ï¼Œç«‹å³å¤§å¹…å¢åŠ æ¢ç´¢
            self.exploration_factor = min(0.9, self.exploration_factor + 0.15)
            self.temperature = min(1.3, self.base_temperature + 0.3)
            logger.warning(f"è¿ç»­ä¸‹é™æ¨¡å¼: å¤§å¹…å¢åŠ æ¢ç´¢ï¼Œæ¸©åº¦={self.temperature:.2f}")
        elif self.stagnation_count >= 2:
            # åœæ»ï¼Œé€‚åº¦å¢åŠ æ¢ç´¢
            self.exploration_factor = min(0.7, self.exploration_factor + 0.1)
            self.temperature = min(1.1, self.base_temperature + 0.2)
            logger.info(f"åœæ»æ¨¡å¼: å¢åŠ æ¢ç´¢ï¼Œæ¸©åº¦={self.temperature:.2f}")
        elif self.improvement_streak >= 3:
            # è¿ç»­æ”¹è¿›ï¼Œä¸“æ³¨åˆ©ç”¨
            self.exploration_factor = max(0.1, self.exploration_factor - 0.05)
            self.temperature = max(0.6, self.base_temperature - 0.1)
            logger.info(f"åˆ©ç”¨æ¨¡å¼: ä¸“æ³¨å½“å‰æ–¹å‘ï¼Œæ¸©åº¦={self.temperature:.2f}")
        elif short_trend > 0.02:  # å•è½®å¤§å¹…æ”¹è¿›
            # å‘ç°å¥½æ–¹å‘ï¼Œé€‚åº¦åˆ©ç”¨
            self.exploration_factor = max(0.2, self.exploration_factor - 0.03)
            self.temperature = max(0.7, self.base_temperature - 0.05)
            logger.info(f"å‘ç°æ”¹è¿›: é€‚åº¦åˆ©ç”¨ï¼Œæ¸©åº¦={self.temperature:.2f}")
        else:
            # å¹³è¡¡çŠ¶æ€ï¼Œé€æ¸å›å½’åŸºå‡†
            target_exploration = 0.3
            self.exploration_factor += (target_exploration - self.exploration_factor) * 0.3
            self.temperature += (self.base_temperature - self.temperature) * 0.2
        
        logger.info(f"RLç­–ç•¥: æ¸©åº¦={self.temperature:.2f}, æ¢ç´¢={self.exploration_factor:.2f}, çŸ­æœŸè¶‹åŠ¿={short_trend:.4f}, é•¿æœŸè¶‹åŠ¿={long_trend:.4f}")

    def _generate_candidates(self, base_code: str, target_description: str, iteration: int, 
                           current_score: float = 0, current_metrics: Dict = None) -> List[str]:
        """ç”Ÿæˆå€™é€‰ä»£ç """
        candidates = []
        
        # æ„å»ºåŠ¨æ€æç¤º
        constraints = self._build_dynamic_constraints(iteration, current_score, current_metrics)
        if target_description:
            prompt = f"è¯·ä¼˜åŒ–ä»¥ä¸‹Verilogä»£ç ä»¥{target_description}ï¼Œ{constraints}\n\nåŸå§‹ä»£ç ï¼š\n{base_code}\n\nä¼˜åŒ–åçš„ä»£ç ï¼š"
        else:
            prompt = f"è¯·ä¼˜åŒ–ä»¥ä¸‹Verilogä»£ç ä»¥æé«˜æ€§èƒ½å’Œå‡å°‘é¢ç§¯ï¼Œ{constraints}\n\nåŸå§‹ä»£ç ï¼š\n{base_code}\n\nä¼˜åŒ–åçš„ä»£ç ï¼š"
        
        # RLæ¨¡å¼ï¼šå•å€™é€‰ç”Ÿæˆï¼ŒéRLæ¨¡å¼ï¼šå¤šå€™é€‰ç”Ÿæˆ
        for i in range(self.population_size):
            try:
                candidate = self._generate_single_candidate(prompt, iteration, i+1, current_score, current_metrics)
                if not candidate:
                    continue
                if self._is_meaningfully_different(base_code, candidate):
                    logger.debug(f"å€™é€‰ {i+1} é•¿åº¦: {len(candidate)} å­—ç¬¦")
                    candidates.append(candidate)
                else:
                    logger.debug(f"å€™é€‰ {i+1} ä¸åŸºå‡†è¿‡äºç›¸ä¼¼ï¼Œå·²ä¸¢å¼ƒ")
                    if self.rl_mode and (self.stagnation_count >= 2 or self.decline_count >= 1):
                        # RLæ¨¡å¼ä¸‹åœæ»æˆ–ä¸‹é™æ—¶ï¼Œå³ä½¿ç›¸ä¼¼ä¹Ÿä¿ç•™ï¼Œå¢åŠ æ¢ç´¢
                        logger.debug(f"RLæ¢ç´¢æ¨¡å¼ï¼šä¿ç•™ç›¸ä¼¼å€™é€‰ä»¥å¢åŠ å¤šæ ·æ€§ï¼ˆåœæ»:{self.stagnation_count}, ä¸‹é™:{self.decline_count}ï¼‰")
                        candidates.append(candidate)
            except Exception as e:
                logger.warning(f"ç”Ÿæˆå€™é€‰ä»£ç  {i+1} å¤±è´¥: {e}")
        
        logger.info(f"ç”Ÿæˆäº† {len(candidates)} ä¸ªæœ‰æ•ˆå€™é€‰ä»£ç ")
        return candidates

    def _build_dynamic_constraints(self, iteration: int, current_score: float, current_metrics: Dict) -> str:
        """åŸºäºå½“å‰çŠ¶æ€å’ŒRLç­–ç•¥æ„å»ºåŠ¨æ€çº¦æŸæç¤º"""
        base_constraints = (
            "è¦æ±‚ï¼š1) ä¸¥æ ¼ä¿ç•™é¡¶å±‚æ¨¡å—çš„æ¥å£(æ¨¡å—åã€ç«¯å£åˆ—è¡¨ã€ä½å®½ã€æ–¹å‘ã€å‚æ•°)å®Œå…¨ä¸€è‡´ï¼›"
            "2) ä»…ä¿®æ”¹æ¨¡å—ä½“å†…å®ç°ï¼Œä¸æ”¹å˜æ¥å£å’Œæ—¶åºè¯­ä¹‰ï¼›"
            "3) åªè¾“å‡ºä¼˜åŒ–åçš„ Verilog ä»£ç (åŒ…å«å®Œæ•´ module...endmodule)ï¼Œä¸è¦é¢å¤–è¯´æ˜ã€‚"
        )
        
        if not self.rl_mode or not current_metrics:
            return base_constraints
        
        # åŸºäºå½“å‰æŒ‡æ ‡åŠ¨æ€æ·»åŠ ä¼˜åŒ–æ–¹å‘æç¤º
        dynamic_hints = []
        
        if self.exploration_factor > 0.5:
            # é«˜æ¢ç´¢æ¨¡å¼ï¼šé¼“åŠ±å¤§èƒ†ä¼˜åŒ–
            dynamic_hints.append("4) å¯å°è¯•è¾ƒå¤§å¹…åº¦çš„é€»è¾‘é‡æ„ã€èµ„æºå…±äº«ã€æ—¶åºä¼˜åŒ–ç­‰ï¼›")
        else:
            # åˆ©ç”¨æ¨¡å¼ï¼šä¿å®ˆä¼˜åŒ–
            dynamic_hints.append("4) è¿›è¡Œä¿å®ˆçš„å±€éƒ¨ä¼˜åŒ–ï¼Œå¦‚å¸¸é‡æŠ˜å ã€å†—ä½™æ¶ˆé™¤ã€è¡¨è¾¾å¼ç®€åŒ–ç­‰ï¼›")
        
        # åŸºäºå½“å‰ç“¶é¢ˆå’ŒRLçŠ¶æ€æŒ‡å¯¼ä¼˜åŒ–é‡ç‚¹
        if current_metrics:
            area = current_metrics.get('area', 0)
            ff_count = current_metrics.get('num_ff', 0)
            depth = current_metrics.get('logic_depth', 0)
            
            # æ ¹æ®RLçŠ¶æ€è°ƒæ•´ä¼˜åŒ–æ¿€è¿›ç¨‹åº¦
            if self.decline_count >= 2:
                dynamic_hints.append("5) å½“å‰ç­–ç•¥æ•ˆæœä¸ä½³ï¼Œå°è¯•å®Œå…¨ä¸åŒçš„ä¼˜åŒ–æ–¹å‘ï¼šé‡æ–°ç»„ç»‡é€»è¾‘ç»“æ„ã€æ”¹å˜å®ç°æ–¹å¼ï¼›")
            elif self.exploration_factor > 0.6:
                if area > ff_count * 100:
                    dynamic_hints.append("5) æ¿€è¿›é¢ç§¯ä¼˜åŒ–ï¼šå¤§å¹…é‡æ„é€»è¾‘ã€åˆå¹¶ç›¸ä¼¼åŠŸèƒ½ã€ä½¿ç”¨æ›´ç´§å‡‘çš„ç¼–ç æ–¹å¼ï¼›")
                elif ff_count > 10:
                    dynamic_hints.append("5) æ¿€è¿›å¯„å­˜å™¨ä¼˜åŒ–ï¼šé‡æ–°è®¾è®¡çŠ¶æ€æœºã€åˆå¹¶å¯„å­˜å™¨ã€ä½¿ç”¨ç§»ä½å¯„å­˜å™¨ï¼›")
                elif depth > 20:
                    dynamic_hints.append("5) æ¿€è¿›æ—¶åºä¼˜åŒ–ï¼šé‡æ–°åˆ†å±‚é€»è¾‘ã€å¼•å…¥æµæ°´çº¿ã€å¹¶è¡ŒåŒ–è®¡ç®—ï¼›")
                else:
                    dynamic_hints.append("5) æ¢ç´¢æ€§ä¼˜åŒ–ï¼šå°è¯•ä¸åŒçš„å®ç°èŒƒå¼ã€ç¼–ç é£æ ¼ã€ç»“æ„ç»„ç»‡ï¼›")
            else:
                if area > ff_count * 100:
                    dynamic_hints.append("5) ä¿å®ˆé¢ç§¯ä¼˜åŒ–ï¼šé€»è¾‘ç®€åŒ–ã€å¸¸é‡æŠ˜å ã€å†—ä½™æ¶ˆé™¤ï¼›")
                elif ff_count > 10:
                    dynamic_hints.append("5) ä¿å®ˆå¯„å­˜å™¨ä¼˜åŒ–ï¼šå±€éƒ¨çŠ¶æ€åˆå¹¶ã€å¯„å­˜å™¨å¤ç”¨ï¼›")
                elif depth > 20:
                    dynamic_hints.append("5) ä¿å®ˆæ—¶åºä¼˜åŒ–ï¼šè¡¨è¾¾å¼åˆ†è§£ã€å…³é”®è·¯å¾„ç¼“è§£ï¼›")
                else:
                    dynamic_hints.append("5) æ¸è¿›å¼ä¼˜åŒ–ï¼šå°å¹…æ”¹è¿›è¡¨è¾¾å¼ã€ä¼˜åŒ–ä¿¡å·å‘½åã€ä»£ç æ•´ç†ï¼›")
        
        return base_constraints + "".join(dynamic_hints)
    
    def _generate_single_candidate(self, prompt: str, iteration: int, cand_idx: int, 
                                 current_score: float = 0, current_metrics: Dict = None) -> Optional[str]:
        """ç”Ÿæˆå•ä¸ªå€™é€‰ä»£ç """
        # 1) æ„å»ºè¾“å…¥ï¼ˆæ”¯æŒ chat æ¨¡æ¿ï¼Œå¦‚ Qwen ç³»åˆ—ï¼›è‹¥æœªé…ç½®æ¨¡æ¿åˆ™å›é€€çº¯æ–‡æœ¬ï¼‰
        use_chat = hasattr(self.tokenizer, "apply_chat_template") and getattr(self.tokenizer, "chat_template", None)
        # æ™ºèƒ½tokenåˆ†é…ï¼šæ”¯æŒæ›´å¤§è¾“å…¥ï¼ŒåŠ¨æ€è°ƒæ•´ç”Ÿæˆé•¿åº¦
        context_max = self._get_context_window()
        estimated_prompt_tokens = len(prompt) // 3  # æ›´å‡†ç¡®çš„ä¼°ç®—ï¼ˆä¸­æ–‡å­—ç¬¦å¯†åº¦æ›´é«˜ï¼‰
        
        # æ ¹æ®è¾“å…¥é•¿åº¦åŠ¨æ€è°ƒæ•´ç”Ÿæˆtokens
        if estimated_prompt_tokens < 2000:
            # çŸ­è¾“å…¥ï¼šä¿è¯å……è¶³ç”Ÿæˆç©ºé—´
            effective_new = self.max_new_tokens
            input_max = context_max - effective_new - 100
        elif estimated_prompt_tokens < 4000:
            # ä¸­ç­‰è¾“å…¥ï¼šå¹³è¡¡è¾“å…¥å’Œç”Ÿæˆ
            effective_new = max(1024, int(self.max_new_tokens * 0.8))
            input_max = context_max - effective_new - 100
        else:
            # é•¿è¾“å…¥ï¼šä¼˜å…ˆä¿è¯è¾“å…¥å®Œæ•´æ€§ï¼Œä½†ä¿è¯æœ€å°ç”Ÿæˆé•¿åº¦
            min_generation = 768  # æœ€å°ç”Ÿæˆé•¿åº¦
            effective_new = max(min_generation, context_max - estimated_prompt_tokens - 200)
            input_max = context_max - effective_new - 100
        
        if estimated_prompt_tokens > input_max:
            logger.warning(f"è¾“å…¥è¿‡é•¿ï¼ˆä¼°ç®—{estimated_prompt_tokens}tokensï¼‰ï¼Œå¯èƒ½å½±å“ç”Ÿæˆè´¨é‡")
        if self.debug_gen:
            logger.debug(f"context_max={context_max}, input_max={input_max}, effective_new={effective_new}, prompt_est={estimated_prompt_tokens}")
        if use_chat:
            try:
                messages = [
                    {"role": "system", "content": "ä½ æ˜¯ç²¾é€šæ•°å­—ç”µè·¯å’ŒVerilogçš„èµ„æ·±èŠ¯ç‰‡å·¥ç¨‹å¸ˆï¼Œç›®æ ‡æ˜¯ä¼˜åŒ–é¢ç§¯/è§¦å‘å™¨æ•°/é€»è¾‘æ·±åº¦ã€‚"},
                    {"role": "user", "content": prompt},
                ]
                text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
                inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=input_max)
            except Exception:
                inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=input_max)
        else:
            inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=input_max)

        input_len = inputs["input_ids"].shape[1]

        if torch.cuda.is_available():
            inputs = {k: v.cuda() for k, v in inputs.items()}
        
        # 2) ç”Ÿæˆï¼Œä»…è§£ç æ–°å¢ tokensï¼Œé¿å…ç”¨å­—ç¬¦ä¸²åˆ‡ç‰‡é”™ä½
        # åŠ¨æ€è°ƒæ•´ç”Ÿæˆå‚æ•°
        dynamic_top_p = max(0.7, min(0.95, self.base_top_p + (self.exploration_factor - 0.3) * 0.2))
        dynamic_top_k = max(30, min(80, int(self.base_top_k + (self.exploration_factor - 0.3) * 50)))
        dynamic_rep_penalty = max(1.0, min(1.15, self.base_rep_penalty + (self.exploration_factor - 0.3) * 0.1))
        
        if self.debug_gen:
            logger.debug(f"ç”Ÿæˆå‚æ•°: temp={self.temperature:.2f}, top_p={dynamic_top_p:.2f}, top_k={dynamic_top_k}, rep_penalty={dynamic_rep_penalty:.2f}")
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=effective_new,
                temperature=self.temperature,
                do_sample=True,
                top_p=dynamic_top_p,
                top_k=dynamic_top_k,
                repetition_penalty=dynamic_rep_penalty,
                pad_token_id=self.tokenizer.eos_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
            )

        new_tokens = outputs[0][input_len:]
        if new_tokens.numel() == 0:
            return None
        generated_tail = self.tokenizer.decode(new_tokens, skip_special_tokens=True)
        self._maybe_dump_text(iteration, cand_idx, "generated_tail.txt", generated_tail)
        # ä¹Ÿä¿å­˜ promptï¼Œä¾¿äºå¯¹ç…§
        self._maybe_dump_text(iteration, cand_idx, "prompt.txt", prompt)

        # 3) æå–ç”Ÿæˆçš„ä»£ç éƒ¨åˆ†ï¼ˆä¼˜å…ˆä»£ç å—ï¼Œå…¶æ¬¡ module..endmoduleï¼‰
        method = "raw"
        if "```" in generated_tail:
            method = "fenced"
        elif ("module" in generated_tail) and ("endmodule" in generated_tail):
            method = "module"
        code_part = self._extract_code_block(generated_tail).strip()
        if self.debug_gen:
            logger.debug(f"æå–æ–¹æ³•={method}, æå–åé•¿åº¦={len(code_part)}")
        self._maybe_dump_text(iteration, cand_idx, f"extracted_{method}.v", code_part)
        if not code_part:
            # å…œåº•ï¼šè‹¥æ¨¡å‹æŠŠâ€œä¼˜åŒ–åçš„ä»£ç ï¼šâ€é‡å¤äº†ï¼Œè¿›ä¸€æ­¥åˆ‡åˆ†
            if "ä¼˜åŒ–åçš„ä»£ç ï¼š" in generated_tail:
                code_part = generated_tail.split("ä¼˜åŒ–åçš„ä»£ç ï¼š")[-1].strip()

        return code_part.strip() or None
    
    def _evaluate_code(self, code: str) -> Dict[str, Any]:
        """è¯„ä¼°ä»£ç è´¨é‡"""
        module = self._detect_top_module(code) or "top"
        return analyze_verilog_api(code, module)
    
    def _calculate_score(self, metrics: Dict[str, Any]) -> float:
        """è®¡ç®—ç»¼åˆåˆ†æ•°ï¼šé¢ç§¯/FF/æ·±åº¦ä¸é€šè¿‡é¡¹"""
        # å·¥å…·é€šè¿‡é¡¹ï¼šè¯­æ³•/ç»¼åˆ/ç­‰ä»·
        pass_bonus = 0.0
        if metrics.get("syntax_ok"):
            pass_bonus += 1.0
        if metrics.get("synth_ok"):
            pass_bonus += 1.0
        if metrics.get("equiv_ok"):
            pass_bonus += 1.0

        # é¢ç§¯ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        area = max(0.0, float(metrics.get("area", 0)))
        area_score = 1.0 / (1.0 + area / 1000.0)

        # è§¦å‘å™¨æ•°é‡ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰
        ff = max(0.0, float(metrics.get("num_ff", 0)))
        ff_score = 1.0 / (1.0 + ff / 1000.0)

        # é€»è¾‘æ·±åº¦ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        depth = max(0.0, float(metrics.get("logic_depth", 0)))
        depth_score = 1.0 / (1.0 + depth / 10.0)

        # ç»¼åˆï¼šå¼ºè°ƒé¢ç§¯ä¸FFï¼Œå…¶æ¬¡æ·±åº¦ï¼Œå¹¶åŠ å…¥é€šè¿‡é¡¹åŠ åˆ†
        total_score = 0.45 * area_score + 0.35 * ff_score + 0.20 * depth_score + 0.10 * pass_bonus
        return total_score
    
    def save_optimization_report(self, result: Dict[str, Any], output_path: str):
        """ä¿å­˜ä¼˜åŒ–æŠ¥å‘Š"""
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "model_path": self.model_path,
            "optimization_config": {
                "max_iterations": self.max_iterations,
                "population_size": self.population_size,
                "temperature": self.temperature
            },
            "result": result
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'eda'):
            self.eda.cleanup()

    # === è¾…åŠ©æ–¹æ³• ===
    def _has_complete_module(self, text: str) -> bool:
        return ("module" in text) and ("endmodule" in text)

    def _try_fix_module_name(self, code: str, module_name: str) -> str:
        """è‹¥å€™é€‰çš„é¡¶å±‚ module åç§°ä¸æœŸæœ›ä¸åŒï¼Œåˆ™ä»…æ›¿æ¢ç¬¬ä¸€ä¸ª module å£°æ˜çš„åç§°ä¸ºæœŸæœ›åã€‚æ”¯æŒå¯é€‰å‚æ•°å— #(...)."""
        pattern = re.compile(r"(\bmodule\s+)([A-Za-z_][A-Za-z0-9_]*)(\s*(?:#\s*\([\s\S]*?\))?\s*\()", flags=re.IGNORECASE)
        def _repl(m):
            return f"{m.group(1)}{module_name}{m.group(3)}"
        return pattern.sub(_repl, code, count=1)
    
    def _extract_module_name(self, code: str) -> Optional[str]:
        """ä»Verilogä»£ç ä¸­æå–æ¨¡å—å"""
        import re
        pattern = re.compile(r'\bmodule\s+(\w+)', re.IGNORECASE)
        match = pattern.search(code)
        if match:
            return match.group(1)
        return None
    
    def _extract_module_ports(self, code: str, module_name: str) -> Optional[str]:
        """æå– module å¤´éƒ¨æ‹¬å·å†…çš„ç«¯å£åˆ—è¡¨æ–‡æœ¬ã€‚å…¼å®¹å¯é€‰å‚æ•°å—ã€‚"""
        pat = re.compile(rf"\bmodule\s+{re.escape(module_name)}\s*(?:#\s*\([\s\S]*?\))?\s*\(([\s\S]*?)\)\s*;", flags=re.IGNORECASE)
        m = pat.search(code)
        if m:
            return m.group(1)
        return None

    def _extract_module_params(self, code: str, module_name: str) -> Optional[str]:
        """æå– module ååçš„å‚æ•°å— #( ... ) æ–‡æœ¬ï¼ˆåŒ…å«æ‹¬å·ï¼‰ï¼Œè‹¥æ— è¿”å› Noneã€‚"""
        pat = re.compile(rf"\bmodule\s+{re.escape(module_name)}\s*(#\s*\([\s\S]*?\))\s*\(", flags=re.IGNORECASE)
        m = pat.search(code)
        if m:
            return m.group(1)
        return None

    def _align_module_header(self, base_code: str, cand_code: str, module_name: str) -> str:
        """å°†å€™é€‰çš„é¡¶å±‚ module å¤´éƒ¨çš„å‚æ•°å—ä¸ç«¯å£åˆ—è¡¨æ›¿æ¢ä¸ºåŸºå‡†ä»£ç å¯¹åº”éƒ¨åˆ†ï¼Œä»¥æœ€å¤§åŒ–æ¥å£ä¸€è‡´æ€§ã€‚"""
        base_ports = self._extract_module_ports(base_code, module_name)
        base_params = self._extract_module_params(base_code, module_name)
        if not base_ports:
            return cand_code
        # ç»„è£…æ›¿æ¢ï¼šmodule name [params] (ports);
        def _repl(m):
            pre = m.group(1)  # 'module name'
            # è‹¥åŸºå‡†æœ‰å‚æ•°å—åˆ™ä½¿ç”¨ä¹‹ï¼Œå¦åˆ™ä¿æŒå€™é€‰çš„ï¼ˆm.group(2)åŒ…å«å€™é€‰çš„å¯é€‰å‚æ•°å—ï¼‰
            cand_params = m.group(2) or ""
            params_use = base_params if base_params is not None else cand_params
            return f"{pre}{params_use}({base_ports})" + m.group(4)
        pat = re.compile(rf"(\bmodule\s+{re.escape(module_name)}\s*)(#\s*\([\s\S]*?\))?\s*\([\s\S]*?\)(\s*;)", flags=re.IGNORECASE)
        # ç”±äºåˆ†ç»„è°ƒæ•´ï¼Œä¿®æ­£è§„åˆ™ä¸ºï¼špre (group1), params? (group2), we need suffix ; (group3)
        # ä½¿ç”¨æ›´æ˜ç¡®çš„æ›¿æ¢é‡å†™ï¼š
        def _repl2(m):
            pre = m.group(1)
            params_use = base_params if base_params is not None else (m.group(2) or "")
            suffix = m.group(3)
            return f"{pre}{params_use}({base_ports}){suffix}"
        return pat.sub(_repl2, cand_code, count=1)

    def _get_context_window(self) -> int:
        """è·å–æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£å¤§å°"""
        try:
            m = int(getattr(self.tokenizer, "model_max_length", 4096) or 4096)
        except Exception:
            m = 4096
        # è¿‡æ»¤å¼‚å¸¸å¤§å€¼
        if m >= 1_000_000:
            m = 8192  # æé«˜é»˜è®¤ä¸Šé™
        # è®¾å®šå…¨å±€ä¸Šé™ï¼Œæ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡
        m = max(2048, min(m, 32768))  # æ”¯æŒåˆ°32Kä¸Šä¸‹æ–‡
        return m

    # === è°ƒè¯•è¾“å‡º ===
    def _candidate_dir(self, iteration: int, cand_idx: int) -> Optional[str]:
        if not self.debug_gen or not self.debug_dir:
            return None
        d = Path(self.debug_dir) / f"iter_{iteration:02d}" / f"cand_{cand_idx:02d}"
        d.mkdir(parents=True, exist_ok=True)
        return str(d)

    def _maybe_dump_text(self, iteration: int, cand_idx: int, name: str, content: str):
        try:
            d = self._candidate_dir(iteration, cand_idx)
            if not d:
                return
            p = Path(d) / name
            with open(p, 'w', encoding='utf-8') as f:
                f.write(content or "")
        except Exception:
            pass
    def _detect_top_module(self, code: str) -> Optional[str]:
        """ä» Verilog æºç ä¸­è‡ªåŠ¨æ£€æµ‹é¡¶å±‚æ¨¡å—åã€‚
        ç­–ç•¥ï¼š
        1) å»é™¤æ³¨é‡Šåï¼ŒåŒ¹é…ç¬¬ä¸€ä¸ª module å£°æ˜ï¼›
        2) è‹¥å­˜åœ¨åä¸º top çš„æ¨¡å—ï¼Œåˆ™ä¼˜å…ˆè¿”å› topï¼›
        3) å¦åˆ™è¿”å›ç¬¬ä¸€ä¸ªæ¨¡å—åï¼›
        4) è‹¥æœªæ‰¾åˆ°è¿”å› Noneã€‚
        """
        try:
            text = re.sub(r"/\*[\s\S]*?\*/", "", code)  # å—æ³¨é‡Š
            text = re.sub(r"//.*", "", text)               # è¡Œæ³¨é‡Š
            names = re.findall(r"\bmodule\s+([A-Za-z_][A-Za-z0-9_]*)", text)
            if not names:
                return None
            # ä¼˜å…ˆ top
            for n in names:
                if n == "top" or n.lower() == "top":
                    return n
            return names[0]
        except Exception:
            return None
    def _extract_code_block(self, text: str) -> str:
        """ä»ç”Ÿæˆæ–‡æœ¬ä¸­æŠ½å– Verilog ä»£ç å—ã€‚
        ä¼˜å…ˆåŒ¹é… ```verilog / ```systemverilog ä»£ç å—ï¼›å¦åˆ™å›é€€åŒ¹é… module...endmoduleã€‚"""
        # 1) ä¸‰å¼•å·ä»£ç å—
        fence_matches = list(re.finditer(r"```(?:verilog|systemverilog)?\s*\n([\s\S]*?)\n```", text, flags=re.IGNORECASE))
        if fence_matches:
            return fence_matches[-1].group(1).strip()

        # 2) module..endmoduleï¼ˆéè´ªå©ªï¼‰
        mod = re.search(r"\bmodule\b[\s\S]*?\bendmodule\b", text, flags=re.IGNORECASE)
        if mod:
            return mod.group(0).strip()

        # 3) ç›´æ¥è¿”å›åŸæ–‡ï¼ˆå¯èƒ½æ¨¡å‹å·²åªè¾“å‡ºä»£ç ï¼‰
        return text.strip()

    def _normalize_code(self, code: str) -> str:
        """å¯¹ Verilog ä»£ç åšè½»åº¦å½’ä¸€åŒ–ï¼šå»æ³¨é‡Šã€å‹ç¼©å¤šç©ºç™½ã€‚"""
        # å»æ‰ // è¡Œæ³¨é‡Š
        code = re.sub(r"//.*", "", code)
        # å»æ‰ /* */ å—æ³¨é‡Š
        code = re.sub(r"/\*[\s\S]*?\*/", "", code)
        # å‹ç¼©ç©ºç™½
        code = re.sub(r"\s+", " ", code).strip()
        return code

    def _is_meaningfully_different(self, base: str, cand: str, threshold: float = 0.98) -> bool:
        """åˆ¤æ–­å€™é€‰æ˜¯å¦ä¸åŸºå‡†å­˜åœ¨â€œæœ‰æ„ä¹‰å·®å¼‚â€ã€‚
        ä½¿ç”¨å½’ä¸€åŒ–åçš„ç›¸ä¼¼åº¦ï¼Œé»˜è®¤é˜ˆå€¼ä¸º 0.98ï¼ˆè¶Šæ¥è¿‘1è¶Šç›¸ä¼¼ï¼‰ã€‚"""
        base_n = self._normalize_code(base)
        cand_n = self._normalize_code(cand)
        if not cand_n:
            return False
        # å®Œå…¨ç›¸ç­‰ç›´æ¥æ‹’ç»
        if base_n == cand_n:
            return False
        sim = SequenceMatcher(a=base_n, b=cand_n).ratio()
        return sim < threshold


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description="RLæ¨ç†ä¼˜åŒ–å™¨")
    parser.add_argument("--model", required=True, help="SFTæ¨¡å‹è·¯å¾„")
    parser.add_argument("--input", "-i", help="è¾“å…¥Verilogæ–‡ä»¶")
    parser.add_argument("--code", "-c", help="ç›´æ¥è¾“å…¥Verilogä»£ç ")
    parser.add_argument("--target", "-t", default="", help="ä¼˜åŒ–ç›®æ ‡æè¿°")
    parser.add_argument("--iterations", type=int, default=10, help="æœ€å¤§è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--population", type=int, default=5, help="å€™é€‰ä»£ç æ•°é‡")
    parser.add_argument("--temperature", type=float, default=0.8, help="ç”Ÿæˆæ¸©åº¦")
    parser.add_argument("--output", "-o", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # è·å–è¾“å…¥ä»£ç 
    if args.input:
        with open(args.input, 'r', encoding='utf-8') as f:
            input_code = f.read()
    elif args.code:
        input_code = args.code
    else:
        print("è¯·æŒ‡å®šè¾“å…¥æ–‡ä»¶ (--input) æˆ–ç›´æ¥è¾“å…¥ä»£ç  (--code)")
        return
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = RLOptimizer(
        model_path=args.model,
        max_iterations=args.iterations,
        population_size=args.population,
        temperature=args.temperature
    )
    
    try:
        # æ‰§è¡Œä¼˜åŒ–
        result = optimizer.optimize(input_code, args.target)
        
        if result["success"]:
            print("=== ä¼˜åŒ–å®Œæˆ ===")
            print(f"é¢ç§¯æ”¹è¿›: {result['improvement']['area_improvement']:.2f}%")
            print(f"è§¦å‘å™¨æ•°æ”¹è¿›: {result['improvement']['ff_improvement']:.2f}%")
            print(f"é€»è¾‘æ·±åº¦æ”¹è¿›: {result['improvement']['depth_improvement']:.2f}%")
            print(f"æ€»åˆ†æ”¹è¿›: {result['improvement']['score_improvement']:.2f}%")
            
            # ä¿å­˜ç»“æœ
            if args.output:
                output_dir = Path(args.output)
                output_dir.mkdir(exist_ok=True)
                
                # ä¿å­˜ä¼˜åŒ–åçš„ä»£ç 
                with open(output_dir / "optimized_code.v", 'w', encoding='utf-8') as f:
                    f.write(result["optimized_code"])
                
                # ä¿å­˜ä¼˜åŒ–æŠ¥å‘Š
                optimizer.save_optimization_report(result, str(output_dir / "optimization_report.json"))
                
                print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
            else:
                print("\n=== ä¼˜åŒ–åçš„ä»£ç  ===")
                print(result["optimized_code"])
        else:
            print(f"ä¼˜åŒ–å¤±è´¥: {result['error']}")
    
    finally:
        optimizer.cleanup()


if __name__ == "__main__":
    main()
